fe_model_loglog_grouped <- feols(fe_formula_loglog_grouped, data = regression_dt_wide)
# --- 9i. Display Results using etable ---
message("Regression complete.")
print(etable(fe_model_loglog_grouped, digits = 4, digits.stats = 4)) # Use etable for better formatting
complete_cases_dt_loglog_grouped_m1 <- complete_cases_dt_loglog_grouped[distance_miles <= 3]
# --- 9h. Run Fixed Effects Regression using feols ---
message("Running fixed effects regression (feols - log-log - combined categories)...")
fe_model_loglog_grouped <- feols(fe_formula_loglog_grouped, data = regression_dt_wide)
# --- 9i. Display Results using etable ---
message("Regression complete.")
print(etable(fe_model_loglog_grouped, digits = 4, digits.stats = 4)) # Use etable for better formatting
source("~/RAwork/traffic_air_pollution/code/data_merge.R", echo = TRUE)
getwd()
################################################################################
# Match the PEMS traffic census monitors and the CARB NOx monitors
################################################################################
nox_file <- here::here("data-clean", "nox_2011.csv")
message("Loading NOx data...")
nox_2011_dt <- fread(nox_file)
message("Loading PeMS census data...")
pems_census_2011_dt <- fread(pems_file)
source("~/RAwork/traffic_air_pollution/code/data_merge.R", echo = TRUE)
library(mapview)
mapview(pems_map_data,
zcol = "type",
col.regions = "#56B4E9",
layer.name = "PeMS Stations") +
mapview(nox_map_data,
zcol = "type",
col.regions = "#D55E00",
layer.name = "NOx Monitors")
rm(list=ls())
gc()
gc()
library(tidyverse)
library(readr)
# ==============================================================================
# census truck data
# ==============================================================================
library(R.utils)
# the census data is downloaded as compressed
# The following code extract the data and delete the compressed files
source_dir <- here::here("data-raw", "testing")
source_fire
source_dir
col_names_ct <- c("time", "station_ID", "substation_ID", "freeway_ID",
"freeway_direction", "city_ID", "county_ID", "district_ID",
"abs_postmile", "station_type", "station_set_ID", "lane",
"vehicle_class", "vehicle_count", "avg_speed", "violation_count",
"violation_code", "single_axle_count", "single_axle_count_duplicate",
"tandem_axle_count", "tridem_axle_count", "quad_axle_count",
"avg_gross_weight", "gross_weight_distribution", "avg_single_weight",
"avg_tandem_weight", "avg_tridem_weight", "avg_quad_weight",
"avg_length", "length_distribution", "avg_tandem_spacing",
"avg_tridem_spacing", "avg_quad_spacing",
"avg_wheelbase", "wheelbase_distribution", "total_flex_esal_300",
"total_flex_esal_285", "total_rigid_esal_300", "total_rigid_esal_285"
)
# 3. Define the file path
file_path_truck <- here::here("data-raw", "testing", "all_text_tmg_trucks_hour_2010_01_01.txt")
file_path_vc <- here::here("data-raw", "testing", "all_text_tmg_vclass_hour_2010_01_01.txt")
# 4. Read the file
#    Use 'col_names' to apply your list.
truck_data <- read_csv(file_path_truck, col_names = col_names_ct)
vc_data <- read_csv(file_path_vc, col_names = col_names_ct)
View(vc_data)
View(truck_data)
1 + 2
str(truck_data)
truck_data %>% filter(station_ID == c(77670))
truck_data %>% filter(station_ID == c(70420))
truck_data %>% filter(station_ID == c(61600
))
str(truck_data)
summarise(truck_data)
summary(truck_data)
truck_data %>% filter(freeway_ID %in% c(5,10,80,99,15))
truck_data %>% filter(freeway_ID %in% c(5,10,80,99,15)) %>% summary()
truck_data %>% filter(freeway_ID %in% c(5,10,80,99,15)) %>% View()
truck_data %>% filter(freeway_ID %in% c(5,10)) %>% View()
col_names_vc <- c("time", "station_ID", "substation_ID", "freeway_ID",
"freeway_direction", "city_ID", "county_ID", "district_ID",
"abs_postmile", "station_type", "station_set_ID", "total_flow",
"samples", "class0", "class1", "class2", "class3", "class4", "class5",
"class6", "class7", "class8", "class9", "class10", "class11",
"class12", "class13", "class14", "class15"
)
vc_data <- read_csv(file_path_vc, col_names = col_names_vc)
View(vc_data)
summary(vc_data)
View(truck_data)
col_names_vc <- c("time", "station_ID", "substation_ID", "freeway_ID",
"freeway_direction", "city_ID", "county_ID", "district_ID",
"abs_postmile", "station_type", "station_set_ID", "total_flow",
"samples", "class0", "class1", "class2",
"class2_duplicate", "class3", "class4", "class5",
"class6", "class7", "class8", "class9", "class10", "class11",
"class12", "class13", "class14"
)
file_path_vc <- here::here("data-raw", "testing", "all_text_tmg_vclass_hour_2010_01_01.txt")
col_names_vc <- c("time", "station_ID", "substation_ID", "freeway_ID",
"freeway_direction", "city_ID", "county_ID", "district_ID",
"abs_postmile", "station_type", "station_set_ID", "total_flow",
"samples", "class0", "class1", "class2",
"class2_duplicate", "class3", "class4", "class5",
"class6", "class7", "class8", "class9", "class10", "class11",
"class12", "class13", "class14"
)
vc_data <- read_csv(file_path_vc, col_names = col_names_vc)
View(vc_data)
vc_data %>% filter(station_ID == 77670\)
vc_data %>% filter(station_ID == 77670)
vc_data %>% filter(station_ID == 77670) %>% View()
2485 + 2505
col_names_vc <- c("time", "station_ID", "substation_ID", "freeway_ID",
"freeway_direction", "city_ID", "county_ID", "district_ID",
"abs_postmile", "station_type", "station_set_ID", "total_flow",
"samples","class1", "class2", "class3", "class4", "class5",
"class6", "class7", "class8", "class9", "class10", "class11",
"class12", "class13", "class14", "class15")
vc_data <- read_csv(file_path_vc, col_names = col_names_vc)
View(vc_data)
10
+2163
+302
+1
+3
+1
+1
+1
+0
+0
+1
+2
sum(10,
2163,
302,
1,
3,
1,
0,
1,
1,
0,
0,
0,
0,
1,
2
)
truck_data %>% filter(station_ID == 116610) %>% View()
1149 + 6087
1149 + 1387
1142 + 940
#  Read the file the Jan 01, 2010 data to check
truck_data <- read_csv(file_path_truck, col_names = col_names_ct)
vc_data <- read_csv(file_path_vc, col_names = col_names_vc)
View(truck_data)
truck_data <- truck_data %>%
select(time, station_ID, substation_ID, freeway_ID, freeway_direction,
city_ID, county_ID, district_ID, postmile, station_type,
station_set_ID, lane, vehicle_class, vehicle_count)
View(truck_data)
truck_data <- truck_data %>%
select(time, station_ID, substation_ID, freeway_ID, freeway_direction,
city_ID, county_ID, district_ID, abs_postmile, station_type,
station_set_ID, lane, vehicle_class, vehicle_count)
vc_data <- vc_data %>%
select(col_names_vc)
vc_data <- read_csv(file_path_vc, col_names = col_names_vc)
vc_data <- vc_data %>%
select(all_of(col_names_vc))
truck_data <- truck_data %>%
select(time, station_ID, substation_ID, freeway_ID, freeway_direction,
city_ID, county_ID, district_ID, abs_postmile, station_type,
station_set_ID, lane, vehicle_class, vehicle_count) %>%
filter(lane == 0)
truck_data_wide <- pivot_wider(
truck_data,
names_from = vehicle_class,     # Makes new columns from 'vehicle_class'
values_from = vehicle_count,    # Fills them with 'vehicle_count'
names_prefix = "class_",        # Adds "class_" to the new column names
)
View(truck_data_wide)
vc_data_wide <- pivot_wider(
vc_data,
names_from = vehicle_class,     # Makes new columns from 'vehicle_class'
values_from = vehicle_count,    # Fills them with 'vehicle_count'
names_prefix = "class_",        # Adds "class_" to the new column names
)
# 1. The total counts do not make sense.
summary(truck_data_wide)
truck_data_wide %>% filter(station_ID == 116610)
# 2. See station_ID = 116610 in both data
# This station is in I-5
truck_data_wide %>% filter(station_ID == 116610)
# 2. See station_ID = 116610 in both data
# This station is in I-5
truck_data_wide %>% filter(station_ID == 116610) %>% View()
vc_data %>% filter(station_ID == 116610) %>% View()
# The census VC data makes much more sense
summary(vc_data)
vc_data %>% filter(station_ID == 116610) %>% View()
file_path_truck_01012010 <- here::here("data-raw", "testing", "all_text_tmg_trucks_hour_2010_01_01.txt")
file_path_vc_01012010 <- here::here("data-raw", "testing", "all_text_tmg_vclass_hour_2010_01_01.txt")
file_path_vc_0102010 <- here::here("data-raw", "testing", "all_text_tmg_vclass_hour_2010_01_01.txt")
file_path_vc_0102010 <- here::here("data-raw", "testing", "all_text_tmg_vclass_hour_2010_01_02.txt")
file_path_vc_0103010 <- here::here("data-raw", "testing", "all_text_tmg_vclass_hour_2010_01_03.txt")
vc_data_01012010 <- read_csv(file_path_vc_01012010, col_names = col_names_vc)
vc_data_01022010 <- read_csv(file_path_vc_01022010, col_names = col_names_vc)
file_path_vc_01022010 <- here::here("data-raw", "testing", "all_text_tmg_vclass_hour_2010_01_02.txt")
file_path_vc_01032010 <- here::here("data-raw", "testing", "all_text_tmg_vclass_hour_2010_01_03.txt")
#  Read the file the Jan 01, 2010 data to check
truck_data_01012010 <- read_csv(file_path_truck_01012010, col_names = col_names_ct)
vc_data_01012010 <- read_csv(file_path_vc_01012010, col_names = col_names_vc)
vc_data_01022010 <- read_csv(file_path_vc_01022010, col_names = col_names_vc)
vc_data_01032010 <- read_csv(file_path_vc_01032010, col_names = col_names_vc)
truck_data_01012010 <- truck_data_01012010 %>%
select(time, station_ID, substation_ID, freeway_ID, freeway_direction,
city_ID, county_ID, district_ID, abs_postmile, station_type,
station_set_ID, lane, vehicle_class, vehicle_count) %>%
filter(lane == 0) # lane 0 is the sum of all lanes
vc_data_01022010 <- vc_data_01022010 %>%
select(all_of(col_names_vc))
vc_data_01032010 <- vc_data_01032010 %>%
select(all_of(col_names_vc))
truck_data_01012010_wide <- pivot_wider(
truck_data_01012010,
names_from = vehicle_class,     # Makes new columns from 'vehicle_class'
values_from = vehicle_count,    # Fills them with 'vehicle_count'
names_prefix = "class_",        # Adds "class_" to the new column names
)
# 1. For the census truck data, the total counts do not make sense.
# class_0 is the sum of all classes
# the max is 428 vehicles per hour in a day
summary(truck_data_01012010_wide)
summary(vc_data_01022010)
# The census VC data makes much more sense
summary(vc_data_01012010)
vc_data_01012010 <- vc_data_01012010 %>%
select(all_of(col_names_vc))
# The census VC data makes much more sense
summary(vc_data_01012010)
summary(vc_data_01032010)
# 2. See station_ID = 116610 in both data
# This station is in I-5
truck_data_wide %>% filter(station_ID == 116610) %>% View()
vc_site_01012010 <- vc_data_01012010 %>% filter(station_ID == 116610)
vc_site_01022010 <- vc_data_01022010 %>% filter(station_ID == 116610)
vc_site_01032010 <- vc_data_01032010 %>% filter(station_ID == 116610)
# 2. See station_ID = 116610 in both data
# This station is in I-5
truck_site_01012010 <- truck_data_01012010_wide %>% filter(station_ID == 116610)
View(vc_data_01012010)
View(vc_data_01022010)
View(vc_data_01032010)
vc_site_01012010 <- vc_data_01012010 %>% filter(station_ID == 116610)
vc_site_01022010 <- vc_data_01022010 %>% filter(station_ID == 116610)
vc_site_01032010 <- vc_data_01032010 %>% filter(station_ID == 116610)
vc_data_01012010 %>% filter(station_ID == 116610)
View(vc_site_01012010)
View(vc_site_01022010)
View(vc_site_01032010)
940 + 1142
776 + 764
1153 + 1067
(2082 + 1540 + 2220)/3
198 + 273
147 + 181
182 + 241
test1 <- vc_site_01012010[1:2, 14:28]
test1
test2 <- vc_site_01022010[1:2, 14:28]
test2
test3
test3 <- vc_site_01032010[1:2, 14:28]
test3
max(test1, test2, test3)
test1
?sumCol
?colSums
rowSums(test1)
colSums(test1)
test1 <- colSums(test1)
test2 <- colSums(test2)
test3 <- colSums(test3)
test <- bind_rows(test1, test2, test3)
test
summary(test)
summarise(test)
summary(test)
summary(test)
# Load LRS shapefile (downloaded from Caltrans GIS portal)
lrs <- st_read(here::here("data-raw", "State_Highway_Network_Lines", "State_Highway_Network_Lines.shp"))
################################################################################
# try to locate the monitors
library(sf)
route <- 5
target_apm <- 42.570
direction <- c("NB")
# 1. Find segment
seg <- lrs %>%
filter(RouteS == route,
bOdometer <= target_apm,
eOdometer >= target_apm,
Direction == direction)
geom <- st_geometry(seg) %>%
st_line_merge() %>%
st_cast("LINESTRING")
frac <- (target_apm - seg$bOdometer) / (seg$eOdometer - seg$bOdometer)
frac
pt <- st_line_sample(geom, sample = frac) %>%
st_cast("POINT")
pt <- st_transform(pt, 4326)
coords <- st_coordinates(pt)
coords
vc_data %>% filter(freeway_ID == 5)
i5 <- vc_data %>% filter(freeway_ID == 5)
unique(i5$station_ID)
summary(i5)
# ==============================================================================
# PEMS data unpacking
# ==============================================================================
library(R.utils)
source_dir <- here::here("data-raw", "census_VC")
destination_dir <- source_dir
if (!dir.exists(destination_dir)) {
dir.create(destination_dir, recursive = TRUE)
print(paste("Created directory:", destination_path))
}
# This finds all files in your folder that end with ".zip"
gz_files <- list.files(path = source_dir,
pattern = "\\.gz$",
full.names = TRUE)
if (length(zip_files) == 0) {
stop(paste("No .gz files found in:", source_dir,
"\nCheck your 'my_folder_path' and file extensions."))
} else {
print(paste("Found", length(gz_files), "gz files to extract."))
}
stop(paste("No .gz files found in:", source_dir,
"\nCheck your 'my_folder_path' and file extensions."))
print(paste("Found", length(gz_files), "gz files to extract."))
if (length(zip_files) == 0) {
stop(paste("No .gz files found in:", source_dir,
"\nCheck your 'my_folder_path' and file extensions."))
} else {
print(paste("Found", length(gz_files), "gz files to extract."))
}
if (length(gz_files) == 0) {
stop(paste("No .gz files found in:", source_dir,
"\nCheck your 'my_folder_path' and file extensions."))
} else {
print(paste("Found", length(gz_files), "gz files to extract."))
}
for (file_path in gz_files) {
# Print a message to show progress
print(paste("Decompressing:", basename(file_path)))
# Decompress the file.
# The 'destname' is the original file without the .gz
# 'remove = TRUE' automatically deletes the original .gz file
# after it is successfully decompressed.
gunzip(file_path, remove = TRUE)
print(paste("Decompressed and removed:", basename(file_path)))
}
# This finds all files in your folder that end with ".txt"
txt_files <- list.files(path = destination_dir,
pattern = "\\.txt$",
full.names = TRUE)
print("---")
print("Decompression complete!")
print(paste0(length(txt_files), " out of ", length(gz_files), " files decompressed."))
print("Old gz files are deleted.")
rm(list = ls())
gc()
if (!require(pacman)) install.packages("pacman")
pacman::p_load(
tidyverse,
data.table,
sf,
lubridate,
progress,
here
)
# ==============================================================================
# Helper Function to Get Point from LRS (for PeMS census data)
# Note that the postmile we have is absolute postmile (that does not reset to 0
# at county boundary). We use the information about freeway number, direction,
# absolute postmile to get the exact latitude and longitude. (See README file)
# ==============================================================================
get_point_from_lrs <- function(station_info, lrs_data) {
# Takes a single row (as data.table) of unique station info and the LRS data
# Returns a data.table with substation_ID and geometry (or NULL on failure)
route <- station_info$freeway_ID
target_apm <- station_info$abs_postmile # Use the absolute postmile
direction_code <- station_info$freeway_direction
# Map PeMS direction to LRS direction (adjust if needed based on LRS data values)
direction_map <- c("N" = "NB", "S" = "SB", "E" = "EB", "W" = "WB")
direction <- direction_map[direction_code]
# Basic validation
if (is.na(direction) || is.na(target_apm) || is.na(route) || target_apm < 0) {
warning(paste("Invalid direction, route, or postmile (<0) for substation:", station_info$substation_ID,
"Route:", route, "APM:", target_apm, "Dir:", direction_code))
return(NULL)
}
# Filter LRS segments matching Route and Direction, covering the target APM
seg <- lrs_data %>%
filter(RouteS == as.character(route),
Direction == direction,
bOdometer <= target_apm,
eOdometer >= target_apm)
# Handle cases where no direct overlap is found
if (nrow(seg) == 0) {
#seg <- lrs_data %>%
#filter(RouteS == as.character(route),
#       Direction == direction,
#       abs(bOdometer - target_apm) < 0.001 | abs(eOdometer - target_apm) < 0.001)
if (nrow(seg) == 0) {
warning(paste("No LRS segment found for substation:", station_info$substation_ID,
"Route:", route, "APM:", target_apm, "Dir:", direction))
return(NULL)
} else {
# If multiple boundary matches, take the first one
# seg <- seg %>% slice(1)
# Fraction is 0 if matching start, 1 if matching end
frac <- ifelse(abs(target_apm - seg$bOdometer) < 0.001, 0, 1)
}
} else {
# If multiple overlapping segments, take the first one
if (nrow(seg) > 1) {
# Reduced warning frequency
warning(paste("Multiple LRS segments found for substation:", station_info$substation_ID,
"- using first match."))
seg <- seg %>% slice(1)
}
# Calculate fraction along the segment
denominator <- seg$eOdometer - seg$bOdometer
# Avoid division by zero if segment length is zero
if (is.na(denominator) || denominator == 0) {
frac <- 0 # Default to start if segment has no length
} else {
frac <- (target_apm - seg$bOdometer) / denominator
}
}
# Process geometry
geom <- st_geometry(seg) %>%
st_line_merge() %>%
st_cast("LINESTRING") # Ensure it's a single linestring
# Use tryCatch for st_line_sample issues like invalid fraction
pt <- tryCatch({
# Ensure frac is valid before sampling
if (!is.finite(frac) || frac < 0 || frac > 1) {
# Reduced warning frequency
warning(paste("Calculated fraction invalid for substation:", station_info$substation_ID, "Frac:", frac))
return(NULL)
}
st_line_sample(geom, sample = frac) %>%
st_cast("POINT")
}, error = function(e) {
warning(paste("st_line_sample failed for substation:", station_info$substation_ID,
"Route:", route, "APM:", target_apm, "Frac:", frac, "Error:", e$message))
return(NULL)
})
# Final check on the created point
if (is.null(pt) || length(pt) == 0 || st_is_empty(pt)) {
warning(paste("Could not generate point geometry for substation:", station_info$substation_ID))
return(NULL)
}
return(data.table(substation_ID = station_info$substation_ID, geometry = pt))
}
col_types_vc <- c(
time = "character", station_ID = "integer", substation_ID = "integer", freeway_ID = "integer",
freeway_direction = "character", city_ID = "integer", county_ID = "integer", district_ID = "integer",
abs_postmile = "numeric", station_type = "character", station_set_ID = "integer", total_flow = "numeric",
samples = "numeric", class_1 = "numeric", class_2 = "numeric", class_3 = "numeric",
class_4 = "numeric", class_5 = "numeric", class_6 = "numeric", class_7 = "numeric",
class_8 = "numeric", class_9 = "numeric", class_10 = "numeric", class_11 = "numeric",
class_12 = "numeric", class_13 = "numeric", class_14 = "numeric", class_15 = "numeric"
)
# ==============================================================================
# Data Processing Function
# ==============================================================================
start_year <- 2010
end_year <- 2010
# Define Paths
census_data_dir <- here::here("data-raw", "census_VC")
lrs_shapefile_path <- here::here("data-raw", "State_Highway_Network_Lines", "State_Highway_Network_Lines.shp")
# Check Paths
if (!dir.exists(census_data_dir)) stop("PeMS data directory not found: ", census_data_dir)
if (!file.exists(lrs_shapefile_path)) stop("LRS shapefile not found: ", lrs_shapefile_path)
# Find Files
all_txt_files <- list.files(path = census_data_dir,
pattern = "^all_text_tmg_vclass_hour_\\d{4}_\\d{2}_\\d{2}\\.txt$",
full.names = TRUE)
if (length(all_txt_files) == 0) {
warning("No PeMS .txt files found in: ", census_data_dir, ". Returning NULL for PeMS data.")
return(NULL) # Return NULL if no files found
}
file_dates <- ymd(str_extract(basename(all_txt_files), "\\d{4}_\\d{2}_\\d{2}"))
file_years <- year(file_dates)
files_to_process <- all_txt_files[file_years >= start_year & file_years <= end_year]
n_files <- length(files_to_process)
if (n_files == 0) {
warning("No PeMS data files found for years: ", start_year, "-", end_year, ". Returning NULL for PeMS data.")
return(NULL) # Return NULL if no files found for the period
}
message("Found ", n_files, " PeMS files for ", start_year, "-", end_year, ".")
# Import and Combine
message("Importing and combining PeMS data...")
# Import and Combine
message("Importing and combining PeMS Census VC data...")
pb_read <- progress_bar$new(format = "  Reading PeMS census [:bar] :percent eta: :eta (:file)", total = n_files, clear = FALSE, width = 60)
