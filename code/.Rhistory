library(tidyverse)
# ==============================================================================
# census truck data
# ==============================================================================
col_names_ct <- c("time", "station_ID", "substation_ID", "freeway_ID",
"freeway_direction", "city_ID", "county_ID", "district_ID",
"postmile", "station_type", "station_set_ID", "lane",
"vehicle_class", "vehicle_count", "avg_speed", "violation_count",
"violation_code", "single_axle_count", "single_axle_count_duplicate",
"tandem_axle_count", "tridem_axle_count", "quad_axle_count",
"avg_gross_weight", "gross_weight_distribution", "avg_single_weight",
"avg_tandem_weight", "avg_tridem_weight", "avg_quad_weight",
"avg_length", "length_distribution", "avg_tandem_spacing",
"avg_tridem_spacing", "avg_quad_spacing",
"avg_wheelbase", "wheelbase_distribution", "total_flex_esal_300",
"total_flex_esal_285", "total_rigid_esal_300", "total_rigid_esal_285"
)
# 3. Define the file path
file_path <- "C:/Users/chen.13129/Downloads/all_text_tmg_trucks_hour_2021_01_01.txt"
# ==============================================================================
# census truck data
# ==============================================================================
col_names_ct <- c("time", "station_ID", "substation_ID", "freeway_ID",
"freeway_direction", "city_ID", "county_ID", "district_ID",
"postmile", "station_type", "station_set_ID", "lane",
"vehicle_class", "vehicle_count", "avg_speed", "violation_count",
"violation_code", "single_axle_count", "single_axle_count_duplicate",
"tandem_axle_count", "tridem_axle_count", "quad_axle_count",
"avg_gross_weight", "gross_weight_distribution", "avg_single_weight",
"avg_tandem_weight", "avg_tridem_weight", "avg_quad_weight",
"avg_length", "length_distribution", "avg_tandem_spacing",
"avg_tridem_spacing", "avg_quad_spacing",
"avg_wheelbase", "wheelbase_distribution", "total_flex_esal_300",
"total_flex_esal_285", "total_rigid_esal_300", "total_rigid_esal_285"
)
# 3. Define the file path
file_path <- "C:/Users/chen.13129/Downloads/all_text_tmg_trucks_hour_2021_01_01.txt"
# 4. Read the file
#    Use 'col_names' to apply your list.
ct_data <- read_csv(file_path, col_names = col_names_ct)
View(ct_data)
# 1. Install (if you haven't already) and load the readr package
# install.packages("readr")
library(readr)
# 2. Define the path to your metadata file
meta_file_path <- "C:/Users/chen.13129/Downloads/d03_text_meta_2021_02_18.txt"
# 3. Read the file
#    read_tsv() is specifically for tab-separated files.
station_meta <- read_tsv(meta_file_path)
View(station_meta)
source_dir <- "C:/Users/chen.13129/OneDrive - The Ohio State University/Documents/RAwork/traffic_air_pollution/data-raw/traffic_census"
source_dir <- "C:/Users/chen.13129/OneDrive - The Ohio State University/Documents/RAwork/traffic_air_pollution/data-raw/traffic_census"
dir.exists(destination_path)
destination_dir <- source_dir
dir.exists(destination_path)
dir.exists(destination_dir)
if (!dir.exists(destination_dir)) {
dir.create(destination_dir, recursive = TRUE)
print(paste("Created directory:", destination_path))
}
# This finds all files in your folder that end with ".zip"
zip_files <- list.files(path = source_dir,
pattern = "\\.zip$",
full.names = TRUE)
# This finds all files in your folder that end with ".zip"
zip_files <- list.files(path = source_dir,
pattern = "\\.gz$",
full.names = TRUE)
# This finds all files in your folder that end with ".zip"
zip_files <- list.files(path = source_dir,
pattern = "\\.zip$",
full.names = TRUE)
# This finds all files in your folder that end with ".zip"
zip_files <- list.files(path = source_dir,
pattern = "\\.gz$",
full.names = TRUE)
# This finds all files in your folder that end with ".zip"
gz_files <- list.files(path = source_dir,
pattern = "\\.gz$",
full.names = TRUE)
if (length(zip_files) == 0) {
stop(paste("No .gz files found in:", source_dir,
"\nCheck your 'my_folder_path' and file extensions."))
} else {
print(paste("Found", length(gz_files), "gz files to extract."))
}
?gunzip
# ==============================================================================
# census truck data
# ==============================================================================
library(R.utils)
install.packages("R.utils")
# ==============================================================================
# census truck data
# ==============================================================================
library(R.utils)
?gunzip
for (file_path in gz_files) {
# Print a message to show progress
print(paste("Decompressing:", basename(file_path)))
# Decompress the file.
# The 'destname' is the original filename without the .gz
# 'remove = TRUE' automatically deletes the original .gz file
# after it is successfully decompressed.
gunzip(file_path, remove = TRUE)
print(paste("Decompressed and removed:", basename(file_path)))
}
print("---")
print("Decompression complete!")
# This finds all files in your folder that end with ".txt"
txt_files <- list.files(path = destination_dir,
pattern = "\\.txt$",
full.names = TRUE)
print(paste0(length(txt_files), "out of", length(gz_files), " files decompressed."))
print(paste0(length(txt_files), " out of ", length(gz_files), " files decompressed."))
print("Decompression complete!")
print(paste0(length(txt_files), " out of ", length(gz_files), " files decompressed."))
print("Old gz files are deleted.")
print("---")
print("Decompression complete!")
print(paste0(length(txt_files), " out of ", length(gz_files), " files decompressed."))
print("Old gz files are deleted.")
# 3. Define the file path
file_path <- "C:/Users/chen.13129/OneDrive - The Ohio State University/Documents/RAwork/traffic_air_pollution/data-raw/traffic_census/all_text_tmg_trucks_hour_2011_01_01.txt"
# 4. Read the file
#    Use 'col_names' to apply your list.
census_data <- read_csv(file_path, col_names = col_names_ct)
col_names_ct <- c("time", "station_ID", "substation_ID", "freeway_ID",
"freeway_direction", "city_ID", "county_ID", "district_ID",
"postmile", "station_type", "station_set_ID", "lane",
"vehicle_class", "vehicle_count", "avg_speed", "violation_count",
"violation_code", "single_axle_count", "single_axle_count_duplicate",
"tandem_axle_count", "tridem_axle_count", "quad_axle_count",
"avg_gross_weight", "gross_weight_distribution", "avg_single_weight",
"avg_tandem_weight", "avg_tridem_weight", "avg_quad_weight",
"avg_length", "length_distribution", "avg_tandem_spacing",
"avg_tridem_spacing", "avg_quad_spacing",
"avg_wheelbase", "wheelbase_distribution", "total_flex_esal_300",
"total_flex_esal_285", "total_rigid_esal_300", "total_rigid_esal_285"
)
# 3. Define the file path
file_path <- "C:/Users/chen.13129/OneDrive - The Ohio State University/Documents/RAwork/traffic_air_pollution/data-raw/traffic_census/all_text_tmg_trucks_hour_2011_01_01.txt"
# 4. Read the file
#    Use 'col_names' to apply your list.
census_data <- read_csv(file_path, col_names = col_names_ct)
library(readr)
# 4. Read the file
#    Use 'col_names' to apply your list.
census_data <- read_csv(file_path, col_names = col_names_ct)
problems(census_data)
View(census_data)
# 3. Define the file path
file_path <- "C:/Users/chen.13129/OneDrive - The Ohio State University/Documents/RAwork/traffic_air_pollution/data-raw/traffic_census/all_text_tmg_trucks_hour_2021_01_01.txt"
# 4. Read the file
#    Use 'col_names' to apply your list.
census_data_2021 <- read_csv(file_path, col_names = col_names_ct)
View(census_data_2021)
census_data_2021 %>% filter(station_ID == 308512)
library(tidyverse)
census_data_2021 %>% filter(station_ID == 308512)
census_data_2021 %>% filter(station_ID == 308511)
census_data_2021 %>% filter(station_ID == 08511)
census_data_2021 %>% filter(station_ID == 44370)
census_data <- census_data %>%
select(time, station_ID, substation_ID, freeway_ID, freeway_direction,
city_ID, county_ID, district_ID, postmile, station_type,
station_set_ID, lane, vehicle_class, vehicle_count)
census_data_wide <- pivot_wider(
census_data,
names_from = vehicle_class,     # Makes new columns from 'vehicle_class'
values_from = vehicle_count,    # Fills them with 'vehicle_count'
names_prefix = "class_",        # Adds "class_" to the new column names
)
View(census_data_wide)
census_data_wide %>% filter(substation_ID == 1050104)
census_data_wide %>% filter(substation_ID == 3050104)
census_data_wide %>% filter(substation_ID == 3010092)
census_data_wide %>% filter(station_set_ID == 6588)
census_data_wide %>% filter(station_set_ID == "6588")
census_data_wide %>% filter(freeway_ID == 80)
census_data_wide %>% filter(freeway_ID == 80) %>% View()
census_data_wide %>% filter(freeway_ID == 99) %>% View()
# 2. Define the path to your metadata file
meta_file_path <- "C:/Users/chen.13129/OneDrive - The Ohio State University/Documents/RAwork/traffic_air_pollution/data-raw/traffic_census/d03_text_meta_2020_01_30.txt"
# 3. Read the file
#    read_tsv() is specifically for tab-separated files.
station_meta <- read_tsv(meta_file_path)
View(station_meta)
station_meta %>% filter(fwy == 92) %>% View()
station_meta %>% filter(Fwy == 92) %>% View()
# 2. Define the path to your metadata file
meta_file_path <- "C:/Users/chen.13129/OneDrive - The Ohio State University/Documents/RAwork/traffic_air_pollution/data-raw/traffic_census/d03_text_meta_2010_12_11.txt"
# 3. Read the file
#    read_tsv() is specifically for tab-separated files.
station_meta <- read_tsv(meta_file_path)
station_meta %>% filter(Fwy == 92) %>% View()
station_meta %>% filter(Fwy == 92)
station_meta %>% filter(Fwy == 101)
station_meta %>% filter(Fwy == 5)
station_meta %>% filter(Fwy == 5) %>% View()
station_meta %>% filter(Fwy == 5 & County == 89) %>% View()
station_meta %>% filter(Fwy == 5) %>% View()
census_data %>% filter(freeway_ID == 5, county_ID == 67)
census_data_2021 %>% filter(freeway_ID == 10, county_ID == 65)
census_data_2021 %>% filter(county_ID == 89)
census_data_2021 %>% filter(county_ID == 89) %>% View()
census_data_2021 %>% filter(county_ID == 89, freeway_ID == 99) %>% View()
census_data_2021 %>% filter(county_ID == 67, freeway_ID == 99) %>% View()
census_data_wide %>% filter(county_ID == 67, freeway_ID == 5) %>% View()
census_data_wide %>% filter(county_ID == 67, freeway_ID == 80) %>% View()
station_meta %>% filter(County == 67, Fwy == 80)
station_meta %>% filter(County == 67, Fwy == 80) %>% View()
test <- census_data_wide %>% filter(county_ID == 67, freeway_ID == 80)
View(test)
census_data_wide %>% filter(substation_ID == 1114091)
census_data_wide %>% filter(substation_ID == 1118333)
census_data_wide %>% filter(substation_ID == 1118450)
# try to locate the monitors
library(sf)
getwd()
# Load LRS shapefile (downloaded from Caltrans GIS portal)
lrs <- st_read("C:/Users/chen.13129/OneDrive - The Ohio State University/Documents/RAwork/traffic_air_pollution/data-raw/State_Highway_Network_Lines/State_Highway_Network_Lines.shp")
View(lrs)
# 1. Find segment
seg <- lrs %>%
filter(RouteS == route,
bOdometer <= target_apm,
eOdometer >= target_apm)
route <- 101
target_apm <- 691.659
# 1. Find segment
seg <- lrs %>%
filter(RouteS == route,
bOdometer <= target_apm,
eOdometer >= target_apm)
seg
View(seg)
direction <- "N"
# 1. Find segment
seg <- lrs %>%
filter(RouteS == route,
bOdometer <= target_apm,
eOdometer >= target_apm,
Direction == direction)
View(seg)
# 1. Find segment
seg <- lrs %>%
filter(RouteS == route,
bOdometer <= target_apm,
eOdometer >= target_apm)
View(seg)
str(seg)
direction <- c("NB")
str(direction)
# 1. Find segment
seg <- lrs %>%
filter(RouteS == route,
bOdometer <= target_apm,
eOdometer >= target_apm,
Direction == direction)
View(seg)
# 2. Fraction along segment
frac <- (target_apm - seg$bOdometer) / (seg$eOdometer - seg$bOdometer)
frac
# 3. Interpolate point
pt <- st_line_sample(seg$geometry, sample = frac) %>%
st_cast("POINT")
frac
?st_line_sample
str(seh)
str(seg)
st_geometry(seg)
?st_line_merge
geom <- st_geometry(seg) %>%
st_line_merge() %>%
st_cast("LINESTRING")
gemo
geom
st_geometry(seg)
View( st_geometry(seg))
frac <- (81.758 - seg$bOdometer) / (seg$eOdometer - seg$bOdometer)
frac <- (target_apm - seg$bOdometer) / (seg$eOdometer - seg$bOdometer)
frac
pt <- st_line_sample(geom, sample = frac) %>%
st_cast("POINT")
pt <- st_transform(pt, 4326)
coords <- st_coordinates(pt)
coords
View(station_meta)
station_meta %>% filter(Fwy == 101)
station_meta %>% filter(Fwy == 101) %>% View()
coords
route <- 99
target_apm <- 379.799
direction <- c("NB")
# 1. Find segment
seg <- lrs %>%
filter(RouteS == route,
bOdometer <= target_apm,
eOdometer >= target_apm,
Direction == direction)
geom <- st_geometry(seg) %>%
st_line_merge() %>%
st_cast("LINESTRING")
frac <- (target_apm - seg$bOdometer) / (seg$eOdometer - seg$bOdometer)
frac
pt <- st_line_sample(geom, sample = frac) %>%
st_cast("POINT")
pt <- st_transform(pt, 4326)
coords <- st_coordinates(pt)
coords
station_meta %>% filter(Fwy == 99)
station_meta %>% filter(Fwy == 99) %>% View()
census_data %>% filter(freeway_ID == 99, postmile >= 190 & postmile <= 191)
census_data %>% filter(freeway_ID == 99, postmile >= 295 & postmile <= 296)
census_data %>% filter(freeway_ID == 99, postmile >= 295 & postmile <= 297)
census_data %>% filter(freeway_ID == 99, postmile >= 290 & postmile <= 297)
census_data %>% filter(freeway_ID == 99, postmile >= 290 & postmile <= 300)
census_data %>% filter(freeway_ID == 99, postmile >= 280 & postmile <= 300)
station_meta %>% filter(Fwy == 99) %>% View()
census_data %>% filter(freeway_ID == 99, postmile >= 280 & postmile <= 300)
test <- census_data %>% filter(freeway_ID == 99, postmile >= 280 & postmile <= 300)
View(test)
test <- census_data %>% filter(freeway_ID == 99, postmile >= 279 & postmile <= 300)
route <- 99
target_apm <- 280.478
direction <- c("NB")
# 1. Find segment
seg <- lrs %>%
filter(RouteS == route,
bOdometer <= target_apm,
eOdometer >= target_apm,
Direction == direction)
geom <- st_geometry(seg) %>%
st_line_merge() %>%
st_cast("LINESTRING")
frac <- (target_apm - seg$bOdometer) / (seg$eOdometer - seg$bOdometer)
frac
pt <- st_line_sample(geom, sample = frac) %>%
st_cast("POINT")
pt <- st_transform(pt, 4326)
coords <- st_coordinates(pt)
coords
